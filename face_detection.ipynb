{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BpKMr34dVyxc",
    "outputId": "6ca4ed9c-7a88-4746-88ad-5ee15e2411ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-vision-face\n",
      "  Downloading azure_cognitiveservices_vision_face-0.5.0-py2.py3-none-any.whl (66 kB)\n",
      "Collecting msrest>=0.5.0\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-common~=1.1\n",
      "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sures\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2021.10.8)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\sures\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.26.0)\n",
      "Requirement already satisfied: six in c:\\users\\sures\\anaconda3\\lib\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sures\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sures\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sures\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.26.7)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, isodate, msrest, azure-common, azure-cognitiveservices-vision-face\n",
      "Successfully installed azure-cognitiveservices-vision-face-0.5.0 azure-common-1.1.27 isodate-0.6.0 msrest-0.6.21 oauthlib-3.1.1 requests-oauthlib-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade azure-cognitiveservices-vision-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "peZXdTPOVz4o",
    "outputId": "e3a166c9-79b5-4829-ad96-9cd51d2bee54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x0000026272F1F160>, <azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x0000026272F1F5E0>]\n",
      "Number of people detected: 2\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person\n",
    "\n",
    "\n",
    "\n",
    "# This key will serve all examples in this document.\n",
    "KEY = \"ea8c44f876804e43ab35a26a09d59da5\"\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = \"https://recognition-ai.cognitiveservices.azure.com/\"\n",
    "\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "image_url = 'https://lh3.googleusercontent.com/pw/AM-JKLWihuQfkjmAu7AG5xRaoCnB9PI5VI6dZGcXhqVtIMk6L9swLa0M8WziWt0uVOTjTEY03WKKzAppzFt62mbpYT9C5x5n-gI0S8TmfOzUOg2X6CceLspAVqWSKyXN96r7C6YNHSGXUw7xm1wK2utNAAjNXg=w2249-h1686-no?authuser=0'\n",
    "image_name = os.path.basename(image_url)\n",
    "\n",
    "response_detected_faces = face_client.face.detect_with_url(\n",
    "    image_url,\n",
    "    detection_model='detection_03',\n",
    "    recognition_model='recognition_04'\n",
    "\n",
    ")\n",
    "print(response_detected_faces)\n",
    "\n",
    "if not response_detected_faces:\n",
    "    raise Exception('No face detected')\n",
    "\n",
    "print('Number of people detected: {0}'.format(len(response_detected_faces)))\n",
    "\n",
    "response_image = requests.get(image_url)\n",
    "img = Image.open(io.BytesIO(response_image.content))\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "for face in response_detected_faces:\n",
    "    rect = face.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = rect.width + left\n",
    "    bottom = rect.height + top\n",
    "    draw.rectangle(((left, top), (right, bottom)), outline='green', width=5)\n",
    "img.show()\n",
    "img.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Guess a person's emotion & age\n",
    "\n",
    "\n",
    "image_url = 'http://www.historyplace.com/kennedy/president-family-portrait-closeup.jpg'\n",
    "\n",
    "response_detection = face_client.face.detect_with_url(\n",
    "    image_url,\n",
    "    detection_model='detection_01',\n",
    "    recognition_model='recognition_04',\n",
    "    return_face_attributes=['age', 'emotion'],\n",
    ")\n",
    "\n",
    "response_image = requests.get(image_url)\n",
    "img = Image.open(io.BytesIO(response_image.content))\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "\n",
    "for face in response_detection:\n",
    "    age = face.face_attributes.age\n",
    "    emotion = face.face_attributes.emotion\n",
    "    neutral = '{0:.0f}%'.format(emotion.neutral * 100)\n",
    "    happiness = '{0:.0f}%'.format(emotion.happiness * 100)\n",
    "    anger = '{0:.0f}%'.format(emotion.anger * 100)\n",
    "    sandness = '{0:.0f}%'.format(emotion.sadness * 100)\n",
    "\n",
    "    rect = face.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = rect.width + left\n",
    "    bottom = rect.height + top\n",
    "    draw.rectangle(((left, top), (right, bottom)), outline='green', width=5)\n",
    "\n",
    "    draw.text((right + 4, top), 'Age: ' + str(int(age)), fill=(255, 255, 255))\n",
    "    draw.text((right + 4, top+35), 'Neutral: ' + neutral, fill=(255, 255, 255))\n",
    "    draw.text((right + 4, top+70), 'Happy: ' + happiness, fill=(255, 255, 255))\n",
    "    draw.text((right + 4, top+105), 'Sad: ' + sandness, fill=(255, 255, 255))\n",
    "    draw.text((right + 4, top+140), 'Angry: ' + anger, fill=(255, 255, 255))\n",
    "\n",
    "img.show()\n",
    "img.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if a face shows up in other photos/images\n",
    "image='http://www.historyplace.com/kennedy/president-family-portrait-closeup.jpg'\n",
    "response_detected_faces = face_client.face.detect_with_url(\n",
    "    image,\n",
    "    detection_model='detection_03',\n",
    "    recognition_model='recognition_04',  \n",
    ")\n",
    "face_ids = [face.face_id for face in response_detected_faces]\n",
    "\n",
    "img_source = 'http://www.historyplace.com/kennedy/president-family-portrait-closeup.jpg'\n",
    "response_face_source = face_client.face.detect_with_url(\n",
    "    img_source,\n",
    "    detection_model='detection_03',\n",
    "    recognition_model='recognition_04'    \n",
    ")\n",
    "face_id_source = response_face_source[0].face_id\n",
    "\n",
    "matched_faces = face_client.face.find_similar(\n",
    "    face_id=face_id_source,\n",
    "    face_ids=face_ids\n",
    ")\n",
    "response_image = requests.get(image)\n",
    "img = Image.open(io.BytesIO(response_image.content))\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "\n",
    "for matched_face in matched_faces:\n",
    "    for face in response_detected_faces:\n",
    "        if face.face_id == matched_face.face_id:\n",
    "            rect = face.face_rectangle\n",
    "            left = rect.left\n",
    "            top = rect.top\n",
    "            right = rect.width + left\n",
    "            bottom = rect.height + top\n",
    "            draw.rectangle(((left, top), (right, bottom)), outline='green', width=5)\n",
    "img.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "face detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
